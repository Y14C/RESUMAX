"""
Google Gemini API Handler for Resumax Application

This module handles all interactions with Google's Gemini API for resume formatting.

PARAMETERS RECEIVED FROM main.py:
    - api_key: str - Google API key for authentication
    - model_name: str - Selected Gemini model identifier
    - system_prompt: str - System prompt read from Model_API/system-prompt.txt
    - latex_format: str - LaTeX template content read from Latex_formats/ATS.tex
    - extracted_text: str - Plain text content extracted from uploaded resume

RETURNS TO main.py:
    - latex_code: str - Formatted LaTeX resume code generated by Gemini

ERROR HANDLING:
    - All API errors, network issues, authentication failures are raised as exceptions
    - No fallback logic provided - errors propagate to main.py for handling
"""

import google.generativeai as genai
import logging
from typing import List

# Configure logging for this module
logger = logging.getLogger(__name__)

# Hardcoded list of available Gemini models
AVAILABLE_MODELS = [
    "gemini-2.5-pro",           # Gemini 2.5 Pro - Most advanced reasoning model
    "gemini-2.5-flash",         # Gemini 2.5 Flash - Balanced speed and performance
    "gemini-2.5-flash-lite"     # Gemini 2.5 Flash-Lite - Fastest and most cost-efficient
]

# API Configuration
TEMPERATURE = 0.4


def get_available_models() -> List[str]:
    """
    Returns list of available Gemini models for user selection.
    
    CALLED BY: main.py during model selection phase
    RETURNS TO: main.py for display in UI
    """
    return AVAILABLE_MODELS


def format_resume(
    api_key: str,
    model_name: str,
    system_prompt: str,
    latex_format: str,
    extracted_text: str
) -> str:
    """
    Main function to format resume using Gemini API.
    
    CALLED BY: main.py after user configuration and file upload
    
    RECEIVES FROM main.py:
        - api_key: Google API key
        - model_name: Selected model from AVAILABLE_MODELS
        - system_prompt: Content from Model_API/system-prompt.txt
        - latex_format: Content from Latex_formats/ATS.tex
        - extracted_text: Processed text from upload_handler.py/pdf_handler.py
    
    RETURNS TO main.py:
        - Formatted LaTeX resume code as string
    
    RAISES:
        - Exception: For invalid model name, API errors, authentication issues, or unexpected errors
    """
    # Log function entry
    logger.info(f"[AI REQUEST] Gemini format_resume() called with model: {model_name}")
    
    # Validate model name
    if model_name not in AVAILABLE_MODELS:
        raise ValueError(f"Invalid model name: {model_name}. Must be one of {AVAILABLE_MODELS}")
    
    # Configure API key
    genai.configure(api_key=api_key)
    
    # Construct user message with format template and extracted text
    user_message = _build_user_message(latex_format, extracted_text)
    
    # Make API call
    try:
        logger.info(f"[AI REQUEST] Making Gemini API call to {model_name} with temperature {TEMPERATURE}")
        # Initialize model with generation config
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={
                "temperature": TEMPERATURE,
            },
            system_instruction=system_prompt
        )
        
        # Generate content
        response = model.generate_content(user_message)
        
        # Extract LaTeX code from response
        latex_code = _extract_latex_from_response(response)
        
        logger.info(f"[AI RESPONSE] Gemini API call successful - Response length: {len(latex_code)} characters")
        return latex_code
        
    except Exception as e:
        # Handle various Gemini exceptions
        error_message = str(e)
        
        if "API_KEY_INVALID" in error_message or "invalid API key" in error_message.lower():
            logger.error(f"[AI ERROR] Gemini Authentication Error for {model_name}: {error_message}")
            raise Exception(f"Authentication Error: Invalid API key - {error_message}") from e
        elif "quota" in error_message.lower() or "rate" in error_message.lower():
            logger.error(f"[AI ERROR] Gemini Rate Limit Error for {model_name}: {error_message}")
            raise Exception(f"Rate Limit Error: {error_message}") from e
        elif "permission" in error_message.lower():
            logger.error(f"[AI ERROR] Gemini Permission Error for {model_name}: {error_message}")
            raise Exception(f"Permission Error: {error_message}") from e
        else:
            logger.error(f"[AI ERROR] Unexpected error in Gemini API call for {model_name}: {error_message}")
            raise Exception(f"Unexpected error in Gemini API call: {error_message}") from e


def _build_user_message(latex_format: str, extracted_text: str) -> str:
    """
    Constructs the user message combining LaTeX format template and extracted resume text.
    Internal function - not called from outside this module.
    """
    user_message = f"""Here is the LaTeX format template to use:

{latex_format}

---

Here is the resume content to format:

{extracted_text}

---

Please format the above resume content using the provided LaTeX template. Return only the complete LaTeX code, ready to compile."""
    
    return user_message


def _extract_latex_from_response(response) -> str:
    """
    Extracts LaTeX code from Gemini's API response.
    Internal function - not called from outside this module.
    """
    # Gemini returns response with text attribute
    if not response or not hasattr(response, 'text'):
        raise Exception("Empty or invalid response received from Gemini API")
    
    latex_code = response.text
    
    if not latex_code or len(latex_code.strip()) == 0:
        raise Exception("No LaTeX code found in Gemini's response")
    
    return latex_code